{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xzbVGolIg08"
      },
      "source": [
        "# Deep Learning\n",
        "## Actividad 1: Deep Vision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNZMjRUJaNv7"
      },
      "source": [
        "GRUPO 7\n",
        "\n",
        "Alina Oganesyan  \n",
        "Celia Vincent  \n",
        "Orlando Dotollo  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhWjErKXWMTl"
      },
      "source": [
        "# Actividad Deep Vision\n",
        "\n",
        "Diseñar y comparar dos estrategias para la clasificación de imágenes en el dataset CIFAR100 de Keras (https://keras.io/api/datasets/cifar100/)\n",
        "\n",
        "### **Estrategia 1: Red pre-entrenada**\n",
        "\n",
        "La primera estrategia a comparar debe incluir la utilización de redes preentrenadas con el dataset ImageNet, llevando a cabo tareas de *transfer learning* y *fine-tuning* para clasificar los objetos de CIFAR100. Deben compararse al menos dos tipos de arquitecturas (VGGs, ResNet50, Xception, InceptionV3, InceptionResNetV2, MobileNetV2, DenseNet, ResNet...) y se debe seleccionar la que mayor precisión nos dé (información sobre las arquitecturas disponibles en https://keras.io/applications/). Se espera que el ejercicio presente una profunda experimentación haciendo uso todas las técnicas de optimización mostradas en clase de forma justificada para la mejora del rendimiento de la red neuronal (weight regularization, dropout, batch normalization, data augmentation, etc.).\n",
        "\n",
        "### **Estrategia 2: Entrenar desde cero o from scratch**\n",
        "\n",
        "La segunda estrategia a comparar será una red neuronal que se debe diseñar, entrenar y optimizar. Se requiere una justificación empírica de las decisiones que llevaron a la selección de atributos, capas e hiperparámetros a los que se ha llegado. Se espera que el ejercicio presente una profunda experimentación haciendo uso de todas las técnicas de optimización mostradas en clase de forma justificada para la mejora del rendimiento de la red neuronal (weight regularization, dropout, batch normalization, data augmentation...).\n",
        "\n",
        "## Normas a seguir\n",
        "\n",
        "- Se debe entregar un **ÚNICO GOOGLE COLAB notebook** (archivo .ipynb) que incluya las instrucciones presentes y su **EJECUCIÓN!!!**. Debe aparecer todo el proceso seguido (carga de datos, visualización de datos, proceso de entrenamiento y proceso de validación del modelo).\n",
        "- Poner el nombre del grupo en el nombre del archivo y el nombre de todos los integrantes del grupo al inicio del notebook.\n",
        "- Las redes utilizadas deben estar entrenadas y con las métricas extraídas en el conjunto de test.\n",
        "- Es recomendable crear una última sección de texto en el notebook en la que se discutan los diferentes modelos obtenidos y se extraigan las conclusiones pertinentes.\n",
        "\n",
        "## Criterio de evaluación\n",
        "\n",
        "- Seguimiento de las normas establecidas en la actividad.\n",
        "- Efectividad al presentar las comparaciones entre métricas de evaluación de ambos modelos.\n",
        "- Demostración de la utilización de técnicas de optimización para mejorar el rendimiento de los modelos.\n",
        "- Modelos predictivos con rendimiento superior al aleatorio.\n",
        "- Corrección en el uso de algoritmos, modelos y formas idiomáticas en Python.\n",
        "- El código debe poder ejecutarse sin modificación alguna en Google Colaboratory."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0p5cu6LTUiZ"
      },
      "source": [
        "Recomendaciones en el Uso de Colab:\n",
        "\n",
        "- Eliminar las variables innecesarias para liberar RAM mediante la sentencia:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DrTrtlo27sTi"
      },
      "source": [
        "del nombrevariable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B56j_TQR4hJm",
        "outputId": "2f1a9c76-6f4e-4812-fdd4-cdb31d0d0841"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "BASE_FOLDER = '/content/drive/' # Ajustar el directorio raíz de Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Lv-_jfxuwK1X"
      },
      "outputs": [],
      "source": [
        "import pandas\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import LabelBinarizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOLue6CL-fwl",
        "outputId": "da4e428e-b985-49e6-81a6-6aa331b08887"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.15.0\n"
          ]
        }
      ],
      "source": [
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFjm7WwHgpXo",
        "outputId": "7d0c2e8f-6282-434a-91d6-f86aa32a0b6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO]: Loading CIFAR-100 data...\n"
          ]
        }
      ],
      "source": [
        "# Carga de datos\n",
        "print(\"[INFO]: Loading CIFAR-100 data...\")\n",
        "cifar100 = tf.keras.datasets.cifar100\n",
        "((x_train, y_train), (x_test, y_test)) = cifar100.load_data()\n",
        "\n",
        "# CIFAR100 labelnames\n",
        "labelNames = ['apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle', 'bicycle', 'bottle', 'bowl', 'boy', 'bridge', 'bus', 'butterfly', 'camel', 'can', 'castle', 'caterpillar', 'cattle', 'chair', 'chimpanzee', 'clock', 'cloud', 'cockroach', 'couch', 'crab', 'crocodile', 'cup', 'dinosaur', 'dolphin', 'elephant', 'flatfish', 'forest', 'fox', 'girl', 'hamster', 'house', 'kangaroo', 'keyboard', 'lamp', 'lawn_mower', 'leopard', 'lion', 'lizard', 'lobster', 'man', 'maple_tree', 'motorcycle', 'mountain', 'mouse', 'mushroom', 'oak_tree', 'orange', 'orchid', 'otter', 'palm_tree', 'pear', 'pickup_truck', 'pine_tree', 'plain', 'plate', 'poppy', 'porcupine', 'possum', 'rabbit', 'raccoon', 'ray', 'road', 'rocket', 'rose', 'sea', 'seal', 'shark', 'shrew', 'skunk', 'skyscraper', 'snail', 'snake', 'spider', 'squirrel', 'streetcar', 'sunflower', 'sweet_pepper', 'table', 'tank', 'telephone', 'television', 'tiger', 'tractor', 'train', 'trout', 'tulip', 'turtle', 'wardrobe', 'whale', 'willow_tree', 'wolf', 'woman', 'worm']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FoZW7A6ywK1Y",
        "outputId": "984e5d9d-263c-4c8f-a21a-da68196736f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "y_train shape: (50000, 1)\n",
            "x_test shape: (10000, 32, 32, 3)\n",
            "y_test shape: (10000, 1)\n"
          ]
        }
      ],
      "source": [
        "# Imprimir las formas de los datos para verificar\n",
        "print(f'x_train shape: {x_train.shape}')\n",
        "print(f'y_train shape: {y_train.shape}')\n",
        "print(f'x_test shape: {x_test.shape}')\n",
        "print(f'y_test shape: {y_test.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXQLJaanwkqr"
      },
      "source": [
        "### **Estrategia 1: Red pre-entrenada**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jqqi9Yb23A3j"
      },
      "source": [
        "###**Red 1: VGG16**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33ThJmtC0nfx"
      },
      "source": [
        "Como primera red pre-entrenada, elegimos VGG16 por considerarse simple y usar capas convolucionales estándar. Igualmente, aunque la arquitectura sea simple, parece ser pesada, por sus requerimientos de memoria (528MB según la documentación de Keras)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfFOUgwo5IgX"
      },
      "source": [
        "**Acondicionamos los datos de entrenamiento**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdsQHZz_6B6i"
      },
      "source": [
        "Imprimimos los valores mínimos y máximos antes de realizar cualquier cambio para tener una referencia de cómo cambiarán los datos tras el procesamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8AFnOlt34T4c",
        "outputId": "505bcb4d-cdd9-4bee-b9b9-3654e2465a39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "255\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "print(x_train.max())\n",
        "print(x_train.min())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owROwHYe65ER"
      },
      "source": [
        "Realizamos OHE sobre las etiquetas de test y train."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFcGNkqrJj9T",
        "outputId": "df57844b-9ec5-48b9-dea8-3486c19372df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Forma de y_train antes de la conversión: (50000, 1)\n",
            "Forma de y_test antes de la conversión: (10000, 1)\n"
          ]
        }
      ],
      "source": [
        "print(\"Forma de y_train antes de la conversión:\", y_train.shape)\n",
        "print(\"Forma de y_test antes de la conversión:\", y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "v4ICxBN17Fbn"
      },
      "outputs": [],
      "source": [
        "lb = LabelBinarizer()\n",
        "y_train = lb.fit_transform(y_train)\n",
        "y_test = lb.transform(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-WxiFx6NxNW",
        "outputId": "3127e7c2-874e-47de-afc6-8c7402c5c841"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Forma de y_train después de la conversión 1: (50000, 100)\n",
            "Forma de y_test después de la conversión 1: (10000, 100)\n"
          ]
        }
      ],
      "source": [
        "print(\"Forma de y_train después de la conversión 1:\", y_train.shape)\n",
        "print(\"Forma de y_test después de la conversión 1:\", y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJWJDRMj8B_1"
      },
      "source": [
        "Importamos la arquitectura VGG16 y aplicamos el preprocesamiento  necesario específicamente para esta red neuronal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "VJPH2DB98AgQ"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import vgg16\n",
        "x_train = vgg16.preprocess_input(x_train)\n",
        "x_test = vgg16.preprocess_input(x_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NaO1AEPR8hR7"
      },
      "source": [
        "Comprobamos cómo han cambiado los datos tras el procesamiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fpgfF7t8lOR",
        "outputId": "7be30fd4-fb36-421e-e790-df0a4acded94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "151.061\n",
            "-123.68\n"
          ]
        }
      ],
      "source": [
        "print(x_train.max())\n",
        "print(x_train.min())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2JZw6tH9Q6X"
      },
      "source": [
        "**Cargamos el base model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XKcbI9yn9bIJ",
        "outputId": "c570e2a1-4778-4dea-8715-e682ebcf212a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 32, 32, 64)        1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 32, 32, 64)        36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 16, 16, 128)       73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 16, 16, 128)       147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 8, 8, 256)         295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 8, 8, 256)         590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 8, 8, 256)         590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 4, 4, 256)         0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 4, 4, 512)         1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 2, 2, 512)         0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14714688 (56.13 MB)\n",
            "Trainable params: 14714688 (56.13 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "base_model = vgg16.VGG16(weights='imagenet',\n",
        "                 include_top=False, # No incluir el Top Model (parte destinada a la clasificación)\n",
        "                 input_shape=(32,32,3))\n",
        "base_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_g7SMd7A615"
      },
      "source": [
        "#### **Transfer Learning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYpkKygmD-mp"
      },
      "source": [
        "**Congelando el modelo base y creando el top model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0r9OaM5KCi4O"
      },
      "source": [
        "Primero importamos las clases necesarios y congelamos el base model, es decir, hacemos que sus pesos no se actualicen durante el entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "3lGRgUUpC3L8"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "base_model.trainable = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhqLZBfhDJV-"
      },
      "source": [
        "Creamos un nuevo modelo secuencial y lo conectamos con nuestro base model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "CDZ3Zu_uDJy3"
      },
      "outputs": [],
      "source": [
        "pre_trained_model = Sequential()\n",
        "pre_trained_model.add(base_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzGBQ8zXDWjA"
      },
      "source": [
        "Ahora, añadimos más capas al nuevo modelo y observamos el resumen de nuestro \"top model\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hRH2aQvqDfYK",
        "outputId": "3b17591e-ec24-41f1-f0a8-0b32e43ae038"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " vgg16 (Functional)          (None, 1, 1, 512)         14714688  \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 256)               131328    \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 100)               25700     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14871716 (56.73 MB)\n",
            "Trainable params: 157028 (613.39 KB)\n",
            "Non-trainable params: 14714688 (56.13 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "pre_trained_model.add(layers.Flatten())\n",
        "pre_trained_model.add(layers.Dense(256, activation='relu'))\n",
        "pre_trained_model.add(layers.Dense(100, activation='softmax'))\n",
        "\n",
        "pre_trained_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HA7hLgX9BJy8"
      },
      "source": [
        "**Entrenando el top model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "WMOi4TaoEIdJ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.layers import Input, Conv2D, Activation, Flatten, Dense, Dropout, BatchNormalization, MaxPooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "from sklearn.metrics import classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXyR0VZMID96",
        "outputId": "db0b29c1-8f11-463c-f7e8-4159dd91851a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO]: Compilando el modelo...\n",
            "[INFO]: Entrenando la red...\n",
            "Epoch 1/20\n",
            "313/313 [==============================] - 663s 2s/step - loss: 3.2217 - accuracy: 0.2729 - val_loss: 3.1933 - val_accuracy: 0.2803\n",
            "Epoch 2/20\n",
            "313/313 [==============================] - ETA: 0s - loss: 2.5174 - accuracy: 0.3804"
          ]
        }
      ],
      "source": [
        "# Compilar el modelo\n",
        "print(\"[INFO]: Compilando el modelo...\")\n",
        "pre_trained_model.compile(loss=\"categorical_crossentropy\", optimizer=Adam(learning_rate=0.0005), metrics=[\"accuracy\"])\n",
        "\n",
        "# Entrenamiento de la red\n",
        "print(\"[INFO]: Entrenando la red...\")\n",
        "H_pre = pre_trained_model.fit(x_train, y_train, batch_size=128, epochs=20, validation_split=0.2)\n",
        "\n",
        "# Montamos la unidad de Drive\n",
        "drive.mount('/content/drive')\n",
        "# Almacenamos el modelo empleando la función mdoel.save de Keras\n",
        "pre_trained_model.save(BASE_FOLDER+\"deepCNN_CIFAR10_pretrained.h5\")\n",
        "\n",
        "# Evaluación del modelo\n",
        "print(\"[INFO]: Evaluando el modelo...\")\n",
        "\n",
        "# Efectuamos la predicción (empleamos el mismo valor de batch_size que en training)\n",
        "predictions = pre_trained_model.predict(x_test, batch_size=128)\n",
        "\n",
        "# Sacamos el report para test\n",
        "print(classification_report(y_test.argmax(axis=1), predictions.argmax(axis=1), target_names=labelNames))\n",
        "\n",
        "# Gráficas\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(np.arange(0, 20), H_pre.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(np.arange(0, 20), H_pre.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.plot(np.arange(0, 20), H_pre.history[\"accuracy\"], label=\"train_acc\")\n",
        "plt.plot(np.arange(0, 20), H_pre.history[\"val_accuracy\"], label=\"val_acc\")\n",
        "plt.title(\"Training Loss and Accuracy\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvEzAuWI53uO"
      },
      "source": [
        "#### **Fine Tuning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkmZs6Vw4Qtl"
      },
      "source": [
        "\n",
        "###**Red 2: MobileNet**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCRhtCGu3TBP"
      },
      "source": [
        "Como segunda red pre-entrenada, elegimos MobileNet por tener una arquitectura muy distinta a la de VGG16, y considerarse un modelo más eficiente (cosa que también comprobamos al mirar sus requerimientos de memoria que en la documentación de Keras son 16MB)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4V6-5yrywva"
      },
      "source": [
        "### **Estrategia 2: Entrenar desde cero o from scratch**"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
